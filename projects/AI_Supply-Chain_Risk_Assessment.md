# AI Supply Chain Risk Assessment

**Vendor:**Â Horizon Labs (AI-Enabled SaaS Provider)  
**Client:**Â Oscorp Industries â€“ R&D Division  
**Analyst:**Â Jose Ruiz-Vazquez  
**Assessment Type:**Â Third-Party AI Risk Assessment (TPRM + AI Governance)  
**Frameworks Applied:**Â NIST AI RMF 1.0, NIST Cybersecurity Framework 2.0, ISO/IEC 42001 (AI Management System), CIS Controls v8.1

---

## ðŸ§¾ Executive Summary

Horizon Labs provides AI-driven data analytics services supporting Oscorpâ€™s bioengineering research.  

Because the SaaS platform processesÂ **scientific and potentially health-related data**Â throughÂ **machine learning models**, the engagement expanded beyond traditional cybersecurity risk to includeÂ **AI-specific governance, transparency, and data-integrity risks**.

The assessment, aligned withÂ **NIST AI RMF**Â andÂ **ISO/IEC 42001**, identified governance and technical gaps across data provenance, model monitoring, and security control maturity.  

While Horizon Labs demonstrates awareness of baseline security practices, its lack of formal AI risk management and model oversight introduces potentialÂ **compliance, reputational, and safety risks**.

| Risk Area                        | Severity  | NIST CSF Domain | NIST AI RMF Function                        | ISO/IEC 42001 Clause          | CIS Control v8.1 | Notes                                     |
| -------------------------------- | --------- | --------------- | ------------------------------------------- | ----------------------------- | ---------------- | ----------------------------------------- |
| Lack of AI governance policy     | ðŸ”´ High   | Govern          | **GOV-1**Â â€“ Establish accountability        | Â§5.3 Leadership               | 17.3             | No defined Responsible AI oversight       |
| Missing data lineage             | ðŸ”´ High   | Identify        | **MAP-2**Â â€“ Document data inputs            | Â§8.2.2 Data management        | 3.1              | Risk to model integrity & reproducibility |
| No bias or explainability review | ðŸŸ  Medium | Protect         | **MEA-1**Â â€“ Assess AI trustworthiness       | Â§8.2.3 Model development      | 10.2             | Transparency & ethical risk               |
| No vuln. mgmt / pen-testing      | ðŸ”´ High   | Protect         | **MAN-2**Â â€“ Mitigate system vulnerabilities | Â§8.2.4 Security controls      | 7.3 / 18.1       | Technical debt in model infrastructure    |
| Informal AI incident response    | ðŸŸ  Medium | Respond         | **MAN-4**Â â€“ Respond to AI failures          | Â§8.3 Monitoring & improvement | 17.1             | No defined AI failure escalation path     |

---

## ðŸ“Š Risk Visualization

![Horizon Labs AI Risk Heatmap](assets/images/Horizon_Labs_AI_TPRM_Heatmap.png)

**Figure: Horizon Labs AI Supply Chain Risk Heatmap**  
This visualization maps vendor control gaps acrossÂ **AI RMF**Â andÂ **CSF**Â categories, emphasizing the overlap between traditional cybersecurity and AI system governance.  

High-impact findings cluster inÂ **Govern**Â (accountability and oversight) andÂ **Manage**Â (incident response and resilience), reflecting early-stage maturity common to emerging AI vendors.

---

## ðŸ§  Analyst Commentary

- **AI Governance Integration:**  
    The lack of formal AI oversight mechanismsâ€”such as a Responsible AI policy or model documentationâ€”creates systemic risk as AI becomes central to Oscorpâ€™s R&D operations.
    
- **Data & Model Integrity Risks:**  
    Absence of data provenance tracking reduces the ability to detect data poisoning or model drift, critical to ensuring trustworthy AI outcomes.
    
- **Bridging Cyber & AI Controls:**  
    Mapping AI RMFâ€™sÂ **Governâ€“Mapâ€“Measureâ€“Manage**Â functions alongside NIST CSF clarified how cybersecurity baselines extend into AI governanceâ€”especially in ensuring confidentiality, integrity, and explainability.
    

---

## ðŸ“ˆ Recommended Next Steps

1. **Establish a Responsible AI Governance Policy:**  
    Define roles, accountability, and model oversight procedures (AI RMF GOV-1, ISO/IEC 42001 Â§5.3).
    
2. **Implement Data Provenance and Model Documentation:**  
    Maintain lineage records and publish model cards summarizing data sources, bias checks, and limitations.
    
3. **Adopt Continuous Vulnerability and Model Risk Management:**  
    Integrate both cybersecurity and AI-specific monitoring (e.g., adversarial testing, dataset validation).
    
4. **Develop AI-Incident Response Playbook:**  
    Include procedures for handling model errors, ethical escalations, and retraining events.
    
5. **Align with ISO/IEC 42001 Certification Path:**  
    Position Horizon Labs for compliance with emerging AI management system standards.
    

---

## ðŸŽ“ Learning Reflection

- Extending a traditionalÂ **TPRM engagement into an AI supply chain context**Â revealed howÂ **AI systems amplify existing vendor risks**â€”from data handling to accountability gaps.
    
- ApplyingÂ **NIST AI RMF**Â in tandem withÂ **NIST CSF**Â demonstrated the importance ofÂ **integrating trustworthiness, transparency, and security**Â into vendor evaluations.
    
- This project reinforced thatÂ **AI governance is not separate from cybersecurity GRC**â€”it is its natural evolution.
    

---

## ðŸ§© References

- [NIST AI Risk Management Framework 1.0](https://www.nist.gov/itl/ai-risk-management-framework)
    
- [ISO/IEC 42001:2023 â€“ AI Management System Standard](https://www.iso.org/standard/81230.html)
    
- [NIST Cybersecurity Framework 2.0](https://www.nist.gov/cyberframework)
    
- [CIS Controls v8.1](https://www.cisecurity.org/controls)
    
- [ENISA AI Threat Landscape 2023](https://www.enisa.europa.eu/publications/artificial-intelligence-threat-landscape)
    

**Artifact Type:**Â AI Supply Chain Risk Assessment Report  
**Estimated Effort:**Â 4â€“5 hours  
**Learning Focus:**Â AI RMF mapping, Responsible AI governance, vendor risk assessment
